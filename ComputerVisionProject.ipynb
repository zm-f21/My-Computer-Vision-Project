{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3BCBLWEHPxeW"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zm-f21/My-Computer-Vision-Project/blob/Branch-3/ComputerVisionProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1> <b> Object Detection Using YOLO <b> </h1></center>"
      ],
      "metadata": {
        "id": "URt4Q-TNmNDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tutorial is designed to provide a comprehensive understanding of how to use YOLO, a state-of-the-art method in computer vision, for detecting objects in images.\n",
        "\n",
        "Object detection and classification is a key technology in many areas, such as automated vehicles, security, and even healthcare.\n",
        "\n",
        "We will begin with the basics of preparing (pre processing) an image dataset, ensuring it is ready for effective model training.We will then explore how YOLO, a type of convolutional neural network, automatically extracts features from images to recognize different objects. Understanding this process is crucial for grasping how YOLO operates.\n",
        "\n",
        "The core of this tutorial is focused on transfer learning using YOLO. We will teach you how to take a pre-trained YOLO model and adapt it to a new dataset. This technique is efficient and powerful, allowing us to harness the strengths of YOLO with less computational effort.\n",
        "\n",
        "By the end of this tutorial, you will have hands-on experience with preparing data, implementing YOLO, and understanding the principles behind it. This tutorial aims to equip students with practical skills and knowledge in one of the most exciting fields in technology."
      ],
      "metadata": {
        "id": "ZIi4bjh7mIJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since its inception, the YOLO family of object detection models has come a long way. YOLOv8 is the most recent addition to this famous anchor-based single-shot family of object detectors. It comes with a bunch of improvements which include state-of-the-art accuracy and speed.  In this article, we will be fine tuning the YOLOv8 object detection model on a real-world pothole detection dataset."
      ],
      "metadata": {
        "id": "vsmlgXapu5rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous lecture, you were asked to make your own custom datasets for a project you want to work on. Today we will explore how to finetune YOLO on a certain dataset.  "
      ],
      "metadata": {
        "id": "v5zL0avFnNaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required Libraries"
      ],
      "metadata": {
        "id": "rr-j-jCmaHId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resources:\n",
        "# Yolo Classification Model: https://docs.ultralytics.com/tasks/classify/#val"
      ],
      "metadata": {
        "id": "-4UGKW3X7ja8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only run the code below when you want to clear files:\n",
        "# !rm -rf /content/*"
      ],
      "metadata": {
        "id": "GNNIiYig7l6t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create a folder for the unzipped files\n",
        "os.makedirs(\"/content/Styles_unzipped\", exist_ok=True)\n",
        "\n",
        "# Unzip the file into that folder\n",
        "with zipfile.ZipFile(\"/content/Styles.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/Styles_unzipped\")\n",
        "\n",
        "# Verify contents\n",
        "os.listdir(\"/content/Styles_unzipped\")\n"
      ],
      "metadata": {
        "id": "Qeb4_GgaaiRZ",
        "outputId": "08a16b74-5bab-448e-9248-6e4f9a66f62b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Styles']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import shutil\n",
        "import os, random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# #/\n",
        "# base_dir = \"/content/asset_styles\"\n",
        "# os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# # Paths for train/val/test\n",
        "# for split in [\"train\", \"val\", \"test\"]:\n",
        "#     os.makedirs(os.path.join(base_dir, split), exist_ok=True)\n",
        "#     /#\n"
      ],
      "metadata": {
        "id": "3_BT3x6HaFLn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# OLD CODE OCT 26:\n",
        "# The Code Below is the same as the Code Above but it resizes large images to\n",
        "# avoid bomb decrompression and to convert tranparent images into RGB\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIG ---\n",
        "source_dir = \"/content/Styles_unzipped\"   # parent folder\n",
        "output_base = \"/content/asset_styles_yolo\"       # YOLO-ready dataset output\n",
        "splits = {\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}\n",
        "augment = True  # enable data augmentation\n",
        "\n",
        "# --- Step 1: Create split folders ---\n",
        "for split in splits.keys():\n",
        "    os.makedirs(os.path.join(output_base, split), exist_ok=True)\n",
        "\n",
        "# --- Step 2: Loop through style folders (Cartoon Stylized, Pixel Art, Vector Art) ---\n",
        "style_folders = [f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))]\n",
        "\n",
        "for style in style_folders:\n",
        "    style_path = os.path.join(source_dir, style)\n",
        "    label_name = style.replace(\" \", \"_\")  # YOLO doesnâ€™t like spaces in class names\n",
        "\n",
        "    # Create subfolders for each split\n",
        "    for split in splits.keys():\n",
        "        os.makedirs(os.path.join(output_base, split, label_name), exist_ok=True)\n",
        "\n",
        "    # Collect all image paths from all subfolders (Background, Characters, Object, UI, etc.)\n",
        "    image_paths = []\n",
        "    for root, _, files in os.walk(style_path):\n",
        "        for f in files:\n",
        "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "                image_paths.append(os.path.join(root, f))\n",
        "\n",
        "    print(f\"ğŸ“‚ Found {len(image_paths)} images for {label_name}\")\n",
        "\n",
        "    # Shuffle and split\n",
        "    random.shuffle(image_paths)\n",
        "    n = len(image_paths)\n",
        "    train_end = int(splits[\"train\"] * n)\n",
        "    val_end = int((splits[\"train\"] + splits[\"val\"]) * n)\n",
        "\n",
        "    split_data = {\n",
        "        \"train\": image_paths[:train_end],\n",
        "        \"val\": image_paths[train_end:val_end],\n",
        "        \"test\": image_paths[val_end:]\n",
        "    }\n",
        "\n",
        "    # --- Step 3: Copy and augment images ---\n",
        "    for split, imgs in split_data.items():\n",
        "        dest_dir = os.path.join(output_base, split, label_name)\n",
        "        for img_path in tqdm(imgs, desc=f\"{label_name} â†’ {split}\"):\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                    # --- Fix transparency / color mode ---\n",
        "                    if img.mode == \"RGBA\":\n",
        "                        img = img.convert(\"RGB\")\n",
        "\n",
        "                    # --- Resize if image is very large ---\n",
        "                    if max(img.size) > 2048:\n",
        "                        img.thumbnail((2048, 2048))  # keeps aspect ratio\n",
        "\n",
        "                    base_name = os.path.basename(img_path)\n",
        "                    save_path = os.path.join(dest_dir, base_name)\n",
        "                    img.save(save_path)\n",
        "\n",
        "                    # --- Step 4: Data Augmentation (optional) ---\n",
        "                    if augment and split == \"train\":\n",
        "                        # Horizontal Flip\n",
        "                        flipped = ImageOps.mirror(img)\n",
        "                        flipped.save(os.path.join(dest_dir, \"flip_\" + base_name))\n",
        "\n",
        "                        # Vertical Flip\n",
        "                        flipped_v = ImageOps.flip(img)\n",
        "                        flipped_v.save(os.path.join(dest_dir, \"vflip_\" + base_name))\n",
        "\n",
        "                        # Small Rotation (-15 to +15 degrees)\n",
        "                        angle = random.uniform(-15, 15)\n",
        "                        rotated = img.rotate(angle, expand=True)\n",
        "                        rotated.save(os.path.join(dest_dir, f\"rot{int(angle)}_\" + base_name))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Skipping {img_path}: {e}\")\n",
        "\n",
        "print(\"\\nâœ… Dataset prepared successfully in YOLO classification format!\")\n",
        "print(f\"ğŸ“ Output location: {output_base}\")\n"
      ],
      "metadata": {
        "id": "8zZfEJ-GlKJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fb8479-e803-4f97-a7f4-9c2db76e4e5f",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Found 100 images for Hand_Painted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hand_Painted â†’ train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [01:51<00:00,  1.60s/it]\n",
            "Hand_Painted â†’ val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:10<00:00,  1.76it/s]\n",
            "Hand_Painted â†’ test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:03<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Found 100 images for Pixel_Art\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pixel_Art â†’ train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:08<00:00,  7.92it/s]\n",
            "Pixel_Art â†’ val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.05it/s]\n",
            "Pixel_Art â†’ test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 22.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Found 109 images for Cartoon_Stylized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cartoon_Stylized â†’ train:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 37/76 [00:29<00:25,  1.52it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:3452: DecompressionBombWarning: Image size (93651448 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "Cartoon_Stylized â†’ train:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 72/76 [01:05<00:02,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Skipping /content/Styles_unzipped/Cartoon Stylized/Objects/cartoon_obj_24.png: Image size (488023972 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cartoon_Stylized â†’ train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [01:10<00:00,  1.08it/s]\n",
            "Cartoon_Stylized â†’ val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:12<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Skipping /content/Styles_unzipped/Cartoon Stylized/Objects/cartoon_obj_22.png: Image size (277788889 pixels) exceeds limit of 178956970 pixels, could be decompression bomb DOS attack.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cartoon_Stylized â†’ test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:05<00:00,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Found 0 images for .ipynb_checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".ipynb_checkpoints â†’ train: 0it [00:00, ?it/s]\n",
            ".ipynb_checkpoints â†’ val: 0it [00:00, ?it/s]\n",
            ".ipynb_checkpoints â†’ test: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Found 100 images for Vector_Art\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Vector_Art â†’ train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:26<00:00,  2.61it/s]\n",
            "Vector_Art â†’ val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  4.33it/s]\n",
            "Vector_Art â†’ test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Dataset prepared successfully in YOLO classification format!\n",
            "ğŸ“ Output location: /content/asset_styles_yolo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "folder_path = \"/content/asset_styles_yolo\"\n",
        "\n",
        "# Check if the folder exists before deleting\n",
        "if os.path.exists(folder_path):\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"âœ… Deleted folder and all contents: {folder_path}\")\n",
        "else:\n",
        "    print(f\"âš ï¸ Folder not found: {folder_path}\")"
      ],
      "metadata": {
        "id": "Umkf21I46yA5",
        "outputId": "cdf6dbfc-8429-47f1-baeb-4c3a6f4933bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Deleted folder and all contents: /content/asset_styles_yolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW CODE: OCT 29 (FIXED FOR BAD TRANSPARENCY MASK)\n",
        "import os\n",
        "import random\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "Image.MAX_IMAGE_PIXELS = None #to fix the large images\n",
        "\n",
        "# --- CONFIG ---\n",
        "source_dir = \"/content/Styles_unzipped\"         # parent folder\n",
        "output_base = \"/content/asset_styles_yolo\"      # YOLO-ready dataset output\n",
        "splits = {\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}\n",
        "augment = True  # enable data augmentation\n",
        "max_dim = 2048  # cap to avoid decompression bomb\n",
        "pad_color = (114, 114, 114)  # YOLO-style neutral padding\n",
        "\n",
        "# --- Step 1: Create split folders ---\n",
        "for split in splits.keys():\n",
        "    os.makedirs(os.path.join(output_base, split), exist_ok=True)\n",
        "\n",
        "# --- Step 2: Loop through style folders ---\n",
        "style_folders = [f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))]\n",
        "\n",
        "def pad_to_square(img, pad_color=(114, 114, 114)):\n",
        "    \"\"\"Pads non-square images to square shape without resizing.\"\"\"\n",
        "    w, h = img.size\n",
        "    size = max(w, h)\n",
        "    new_img = Image.new(\"RGB\", (size, size), pad_color)\n",
        "    new_img.paste(img, ((size - w) // 2, (size - h) // 2))\n",
        "    return new_img\n",
        "\n",
        "for style in style_folders:\n",
        "    style_path = os.path.join(source_dir, style)\n",
        "    label_name = style.replace(\" \", \"_\").replace(\"-\", \"_\")  # sanitize names\n",
        "\n",
        "    # Create subfolders for each split\n",
        "    for split in splits.keys():\n",
        "        os.makedirs(os.path.join(output_base, split, label_name), exist_ok=True)\n",
        "\n",
        "    # Gather all image paths\n",
        "    image_paths = []\n",
        "    for root, _, files in os.walk(style_path):\n",
        "        for f in files:\n",
        "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "                image_paths.append(os.path.join(root, f))\n",
        "\n",
        "    print(f\"ğŸ“‚ Found {len(image_paths)} images for {label_name}\")\n",
        "\n",
        "    # Shuffle and split\n",
        "    random.shuffle(image_paths)\n",
        "    n = len(image_paths)\n",
        "    train_end = int(splits[\"train\"] * n)\n",
        "    val_end = int((splits[\"train\"] + splits[\"val\"]) * n)\n",
        "\n",
        "    split_data = {\n",
        "        \"train\": image_paths[:train_end],\n",
        "        \"val\": image_paths[train_end:val_end],\n",
        "        \"test\": image_paths[val_end:]\n",
        "    }\n",
        "\n",
        "    # --- Step 3: Process and augment images ---\n",
        "    for split, imgs in split_data.items():\n",
        "        dest_dir = os.path.join(output_base, split, label_name)\n",
        "        for img_path in tqdm(imgs, desc=f\"{label_name} â†’ {split}\"):\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                    # --- FIXED TRANSPARENCY HANDLING ---\n",
        "                    if img.mode in (\"RGBA\", \"LA\"):\n",
        "                        # Handle true alpha channel\n",
        "                        bg = Image.new(\"RGB\", img.size, pad_color)\n",
        "                        bg.paste(img, mask=img.split()[-1])\n",
        "                        img = bg\n",
        "                    elif img.mode == \"P\":\n",
        "                        # Handle palette-based images safely\n",
        "                        if \"transparency\" in img.info:\n",
        "                            try:\n",
        "                                alpha = img.convert(\"RGBA\")\n",
        "                                bg = Image.new(\"RGB\", img.size, pad_color)\n",
        "                                bg.paste(alpha, mask=alpha.split()[-1])\n",
        "                                img = bg\n",
        "                            except Exception:\n",
        "                                img = img.convert(\"RGB\")  # fallback if transparency fails\n",
        "                        else:\n",
        "                            img = img.convert(\"RGB\")\n",
        "                    elif img.mode != \"RGB\":\n",
        "                        img = img.convert(\"RGB\")\n",
        "\n",
        "                    # --- Resize large images ---\n",
        "                    if max(img.size) > max_dim:\n",
        "                        img.thumbnail((max_dim, max_dim), Image.LANCZOS)\n",
        "\n",
        "                    # --- Pad to square (important for YOLO classification) ---\n",
        "                    img = pad_to_square(img, pad_color)\n",
        "\n",
        "                    # --- Save cleaned base image ---\n",
        "                    base_name = os.path.basename(img_path)\n",
        "                    base_name = base_name.replace(\" \", \"_\")  # clean filename\n",
        "                    save_path = os.path.join(dest_dir, base_name)\n",
        "                    img.save(save_path, quality=95)\n",
        "\n",
        "                    # --- Augmentation (train only) ---\n",
        "                    if augment and split == \"train\":\n",
        "                        # Horizontal Flip\n",
        "                        flipped = ImageOps.mirror(img)\n",
        "                        flipped.save(os.path.join(dest_dir, f\"flip_{base_name}\"), quality=95)\n",
        "\n",
        "                        # Vertical Flip\n",
        "                        flipped_v = ImageOps.flip(img)\n",
        "                        flipped_v.save(os.path.join(dest_dir, f\"vflip_{base_name}\"), quality=95)\n",
        "\n",
        "                        # Small Rotation (within safe bounds)\n",
        "                        angle = random.uniform(-15, 15)\n",
        "                        rotated = img.rotate(angle, expand=False, resample=Image.BICUBIC)\n",
        "                        rotated.save(os.path.join(dest_dir, f\"rot{int(angle)}_{base_name}\"), quality=95)\n",
        "\n",
        "            except Exception as e:\n",
        "                # If the image is corrupted or transparency fails, skip gracefully\n",
        "                print(f\"âš ï¸ Skipping {img_path}: {e}\")\n",
        "\n",
        "print(\"\\nâœ… Dataset prepared successfully in YOLO classification format!\")\n",
        "print(f\"ğŸ“ Output location: {output_base}\")"
      ],
      "metadata": {
        "id": "b626xsLntC-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e7c9a8-c357-4a37-a2a2-dc4892a0fbb7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Found 409 images for Styles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Styles â†’ train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 286/286 [05:26<00:00,  1.14s/it]\n",
            "Styles â†’ val:   7%|â–‹         | 6/82 [00:05<01:26,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Skipping /content/Styles_unzipped/Styles/Cartoon Stylized/Objects/cartoon_obj_24.png: image file is truncated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Styles â†’ val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:32<00:00,  2.55it/s]\n",
            "Styles â†’ test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:31<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Dataset prepared successfully in YOLO classification format!\n",
            "ğŸ“ Output location: /content/asset_styles_yolo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "CX_xD9nmiyWb",
        "outputId": "c509f7de-028e-4955-e59c-f81a71431c97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.222 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 41.1/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sympy==1.12\n",
        "!pip install -U torch torchvision torchaudio\n",
        "!pip install -U ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vTR2D_S9vtTt",
        "outputId": "ed3c2720-e067-40bc-94e8-83e7c3dbec5b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy==1.12\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy==1.12) (1.3.0)\n",
            "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.8.0+cu126 requires sympy>=1.13.3, but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.12\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.0 (from torch)\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m688.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.12\n",
            "    Uninstalling sympy-1.12:\n",
            "      Successfully uninstalled sympy-1.12\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvshmem-cu12\n",
            "    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n",
            "    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n",
            "      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.0 torchaudio-2.9.0 torchvision-0.24.0 triton-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia",
                  "torch",
                  "torchgen"
                ]
              },
              "id": "011dfcf8cfb4431683f176caef665333"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.222)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolo11n-cls.pt\")  # pretrained classification model\n",
        "results = model.train(\n",
        "    data=\"/content/asset_styles_yolo\",\n",
        "    epochs=50,\n",
        "    imgsz=224,\n",
        "    batch=8,\n",
        "    lr0=0.001,\n",
        "    weight_decay=0.0005,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NxDoh9Fu3d5",
        "outputId": "758629f3-68b1-42ad-9094-ca6e3ec61faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.221 ğŸš€ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/asset_styles_yolo, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "ERROR âŒ \u001b[34m\u001b[1mtrain:\u001b[0m /content/asset_styles_yolo/train... found 1169 images in 4 classes (requires 5 classes, not 4)\n",
            "ERROR âŒ \u001b[34m\u001b[1mval:\u001b[0m /content/asset_styles_yolo/val... found 78 images in 4 classes (requires 5 classes, not 4)\n",
            "ERROR âŒ \u001b[34m\u001b[1mtest:\u001b[0m /content/asset_styles_yolo/test... found 44 images in 4 classes (requires 5 classes, not 4)\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 10                  -1  1    336645  ultralytics.nn.modules.head.Classify         [256, 5]                      \n",
            "YOLO11n-cls summary: 86 layers, 1,537,509 parameters, 1,537,509 gradients, 3.3 GFLOPs\n",
            "Transferred 234/236 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1262.1Â±933.8 MB/s, size: 237.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/asset_styles_yolo/train... 1169 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1169/1169 1.2Kit/s 1.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/asset_styles_yolo/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.1Â±0.3 ms, read: 371.1Â±226.7 MB/s, size: 402.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/asset_styles_yolo/val... 78 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 78/78 503.3it/s 0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/asset_styles_yolo/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/classify/train2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       1/50     0.344G      1.158          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.1it/s 46.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.7it/s 1.4s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       2/50     0.344G     0.7158          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 40.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 21.5it/s 0.2s\n",
            "                   all       0.59          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       3/50     0.344G     0.6894          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.5it/s 41.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 27.7it/s 0.2s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       4/50     0.344G     0.6762          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.5it/s 42.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 28.2it/s 0.2s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       5/50     0.344G     0.5163          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 40.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 24.5it/s 0.2s\n",
            "                   all      0.641          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       6/50     0.344G     0.5197          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 35.0it/s 0.1s\n",
            "                   all       0.59          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       7/50     0.344G     0.5269          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 39.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 20.0it/s 0.2s\n",
            "                   all       0.59          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       8/50     0.344G     0.4559          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.8it/s 38.6s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 22.1it/s 0.2s\n",
            "                   all      0.628          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       9/50     0.344G     0.4363          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 29.8it/s 0.2s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      10/50     0.344G     0.3785          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 34.8it/s 0.1s\n",
            "                   all      0.641          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      11/50     0.344G     0.3205          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 41.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 30.7it/s 0.2s\n",
            "                   all      0.641          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      12/50     0.344G     0.3747          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.8it/s 39.1s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 18.7it/s 0.3s\n",
            "                   all      0.654          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      13/50     0.344G     0.3319          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 40.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 25.5it/s 0.2s\n",
            "                   all      0.641          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      14/50     0.344G     0.2921          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 26.6it/s 0.2s\n",
            "                   all      0.654          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      15/50     0.344G     0.3175          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 31.4it/s 0.2s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      16/50     0.344G     0.2857          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 39.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 18.6it/s 0.3s\n",
            "                   all      0.679          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      17/50     0.344G     0.2933          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.8it/s 39.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 30.1it/s 0.2s\n",
            "                   all      0.692          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      18/50     0.344G     0.2542          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 31.6it/s 0.2s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      19/50     0.344G     0.2561          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 37.2it/s 0.1s\n",
            "                   all      0.628          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      20/50     0.344G     0.2097          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 22.0it/s 0.2s\n",
            "                   all      0.641          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      21/50     0.344G     0.2071          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.8it/s 38.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 19.3it/s 0.3s\n",
            "                   all      0.705          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      22/50     0.344G     0.2125          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 35.1it/s 0.1s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      23/50     0.344G     0.1921          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.6s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 25.5it/s 0.2s\n",
            "                   all      0.692          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      24/50     0.344G      0.193          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 41.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 20.9it/s 0.2s\n",
            "                   all      0.654          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      25/50     0.344G     0.1784          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 39.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 16.0it/s 0.3s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      26/50     0.344G     0.1843          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.8it/s 38.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 21.2it/s 0.2s\n",
            "                   all      0.705          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      27/50     0.344G     0.1912          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 24.6it/s 0.2s\n",
            "                   all      0.654          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      28/50     0.344G     0.1702          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 20.2it/s 0.2s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      29/50     0.344G     0.1388          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 27.4it/s 0.2s\n",
            "                   all      0.718          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      30/50     0.344G     0.1052          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.8it/s 39.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 24.8it/s 0.2s\n",
            "                   all      0.667          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      31/50     0.344G     0.1415          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 40.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 29.9it/s 0.2s\n",
            "                   all      0.641          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      32/50     0.344G      0.144          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 20.6it/s 0.2s\n",
            "                   all      0.679          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      33/50     0.344G     0.1311          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 27.4it/s 0.2s\n",
            "                   all      0.705          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      34/50     0.344G     0.1327          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 41.2s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 32.8it/s 0.2s\n",
            "                   all      0.679          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      35/50     0.344G     0.1304          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 39.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 14.9it/s 0.3s\n",
            "                   all      0.744          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      36/50     0.344G     0.1204          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.8it/s 38.4s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 24.6it/s 0.2s\n",
            "                   all      0.705          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      37/50     0.344G      0.109          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 31.1it/s 0.2s\n",
            "                   all      0.718          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      38/50     0.344G    0.09788          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 28.7it/s 0.2s\n",
            "                   all      0.654          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      39/50     0.344G     0.1204          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 27.2it/s 0.2s\n",
            "                   all      0.692          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      40/50     0.344G     0.1079          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 36.2it/s 0.1s\n",
            "                   all      0.679          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      41/50     0.344G    0.07132          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 39.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 17.8it/s 0.3s\n",
            "                   all      0.679          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      42/50     0.344G    0.07045          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 39.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 17.4it/s 0.3s\n",
            "                   all      0.692          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      43/50     0.344G    0.06311          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.3it/s 44.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 17.6it/s 0.3s\n",
            "                   all      0.679          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      44/50     0.344G    0.07669          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.7it/s 39.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 16.9it/s 0.3s\n",
            "                   all      0.705          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      45/50     0.344G    0.06779          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 24.8it/s 0.2s\n",
            "                   all      0.718          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      46/50     0.344G    0.07138          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 26.7it/s 0.2s\n",
            "                   all      0.679          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      47/50     0.344G     0.0688          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.6s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 18.5it/s 0.3s\n",
            "                   all      0.718          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      48/50     0.344G    0.05839          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.5it/s 42.1s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 24.8it/s 0.2s\n",
            "                   all      0.731          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      49/50     0.344G    0.08562          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.5it/s 42.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 24.2it/s 0.2s\n",
            "                   all      0.692          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      50/50     0.344G     0.0623          1        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 147/147 3.6it/s 40.6s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 20.6it/s 0.2s\n",
            "                   all      0.705          1\n",
            "\n",
            "50 epochs completed in 0.577 hours.\n",
            "Optimizer stripped from /content/runs/classify/train2/weights/last.pt, 3.2MB\n",
            "Optimizer stripped from /content/runs/classify/train2/weights/best.pt, 3.2MB\n",
            "\n",
            "Validating /content/runs/classify/train2/weights/best.pt...\n",
            "Ultralytics 8.3.221 ğŸš€ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-cls summary (fused): 47 layers, 1,532,429 parameters, 0 gradients, 3.2 GFLOPs\n",
            "ERROR âŒ \u001b[34m\u001b[1mtrain:\u001b[0m /content/asset_styles_yolo/train... found 1169 images in 4 classes (requires 5 classes, not 4)\n",
            "ERROR âŒ \u001b[34m\u001b[1mval:\u001b[0m /content/asset_styles_yolo/val... found 78 images in 4 classes (requires 5 classes, not 4)\n",
            "ERROR âŒ \u001b[34m\u001b[1mtest:\u001b[0m /content/asset_styles_yolo/test... found 44 images in 4 classes (requires 5 classes, not 4)\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 5.7it/s 0.9s\n",
            "                   all      0.744          1\n",
            "Speed: 0.6ms preprocess, 3.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Path to your validation dataset\n",
        "val_dir = \"/content/asset_styles_yolo/val\"\n",
        "\n",
        "# List your class names (must match folder names)\n",
        "class_names = [\"Hand_Painted\", \"Cartoon_Stylized\", \"Pixel_Art\", \"Vector_Art\"]\n",
        "\n",
        "# Load your trained model (trained with nc=5)\n",
        "model = YOLO(\"/content/runs/classify/train2/weights/best.pt\")\n",
        "\n",
        "# Prepare lists to store true and predicted labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Iterate through each class folder\n",
        "for label_idx, class_name in enumerate(class_names):\n",
        "    class_folder = Path(val_dir) / class_name\n",
        "    if not class_folder.exists():\n",
        "        print(f\"Warning: Folder {class_folder} does not exist.\")\n",
        "        continue\n",
        "\n",
        "    # Iterate through each image in the folder\n",
        "    for img_path in class_folder.iterdir():\n",
        "        if img_path.suffix.lower() not in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\"]:\n",
        "            continue  # skip unsupported files\n",
        "\n",
        "        # Run prediction\n",
        "        results = model.predict(source=str(img_path), save=False, verbose=False)\n",
        "        pred_class = results[0].probs.top1  # predicted class index\n",
        "\n",
        "        # Store true and predicted labels\n",
        "        y_true.append(label_idx)\n",
        "        y_pred.append(pred_class)\n",
        "\n",
        "# --- Fix for extra class in the model (ignore predictions of class index 4) ---\n",
        "y_true_filtered = []\n",
        "y_pred_filtered = []\n",
        "\n",
        "for t, p in zip(y_true, y_pred):\n",
        "    if p < len(class_names):  # keep only predictions for valid classes (0-3)\n",
        "        y_true_filtered.append(t)\n",
        "        y_pred_filtered.append(p)\n",
        "\n",
        "# Compute metrics\n",
        "precision = precision_score(y_true_filtered, y_pred_filtered, average='macro', zero_division=0)\n",
        "recall = recall_score(y_true_filtered, y_pred_filtered, average='macro', zero_division=0)\n",
        "f1 = f1_score(y_true_filtered, y_pred_filtered, average='macro', zero_division=0)\n",
        "cm = confusion_matrix(y_true_filtered, y_pred_filtered, labels=list(range(len(class_names))))\n",
        "\n",
        "# Print results\n",
        "print(\"Top-1 Accuracy:\", metrics.top1)\n",
        "print(\"Top-5 Accuracy:\", metrics.top5)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "660BB9J0Qren",
        "outputId": "5bdab436-2896-48ba-a2b5-4baccfacd3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-1 Accuracy: 0.7435897588729858\n",
            "Top-5 Accuracy: 1.0\n",
            "Precision: 0.18245341614906835\n",
            "Recall: 0.275\n",
            "F1 Score: 0.1922094508301405\n",
            "Confusion Matrix:\n",
            " [[ 0  2 16  1]\n",
            " [ 0  9  4  2]\n",
            " [ 0  1  0 18]\n",
            " [ 0  2  0  2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# --- Assume y_true_filtered and y_pred_filtered are already computed ---\n",
        "# Example:\n",
        "# y_true_filtered = [...]\n",
        "# y_pred_filtered = [...]\n",
        "class_names = [\"Hand_Painted\", \"Cartoon_Stylized\", \"Pixel_Art\", \"Vector_Art\"]\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true_filtered, y_pred_filtered, labels=list(range(len(class_names))))\n",
        "\n",
        "# Create a figure\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot using seaborn heatmap\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Save to file\n",
        "save_path = '/content/runs/classify/val/confusion_matrix.png'\n",
        "plt.savefig(save_path, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"âœ… Confusion matrix saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "cUzhow3ZMWqd",
        "outputId": "a9fa4af2-6d81-490a-890f-141f2b31b377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Confusion matrix saved to /content/runs/classify/val/confusion_matrix.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have already computed:\n",
        "# metrics.top1, metrics.top5, and filtered precision, recall, f1\n",
        "metrics_dict = {\n",
        "    \"Top-1 Accuracy\": metrics.top1,\n",
        "    \"Top-5 Accuracy\": metrics.top5,\n",
        "    \"Precision\": precision,  # from your filtered evaluation\n",
        "    \"Recall\": recall,        # from your filtered evaluation\n",
        "    \"F1 Score\": f1           # from your filtered evaluation\n",
        "}\n",
        "\n",
        "# Save to CSV\n",
        "save_path = \"/content/classification_metrics.csv\"\n",
        "pd.DataFrame([metrics_dict]).to_csv(save_path, index=False)\n",
        "print(f\"âœ… Metrics saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYUJqzkTMYdU",
        "outputId": "3b865b17-c1db-4102-b399-1db2592744b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Metrics saved to /content/classification_metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "# Load your trained model (use the best weights)\n",
        "model = YOLO(\"/content/runs/classify/train/weights/best.pt\")\n",
        "\n",
        "# Path to your test image\n",
        "test_image = \"/content/Styles_unzipped/Pixel Art/Background/pixel_bg_05.png\"  # change this to any image path\n",
        "\n",
        "# Run prediction\n",
        "results = model.predict(source=test_image, show=True)\n",
        "\n",
        "# Print predicted class\n",
        "print(\"Predicted class:\", results[0].names[results[0].probs.top1])\n",
        "print(\"Confidence:\", results[0].probs.top1conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKA26iWlNLLf",
        "outputId": "a5617818-0c85-4e31-de8a-1c67f369044d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "\n",
            "image 1/1 /content/Styles_unzipped/Pixel Art/Background/pixel_bg_05.png: 224x224 IAT_360_CV_Project_Data 1.00, 5.6ms\n",
            "Speed: 3.2ms preprocess, 5.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Predicted class: IAT_360_CV_Project_Data\n",
            "Confidence: tensor(1., device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "\n",
        "# Load trained model\n",
        "model = YOLO(\"/content/runs/classify/train/weights/best.pt\")\n",
        "\n",
        "# Path to test image\n",
        "test_image = \"/content/Styles_unzipped/Pixel Art/Background/pixel_bg_05.png\"\n",
        "\n",
        "# Run prediction\n",
        "results = model.predict(source=test_image, verbose=False)\n",
        "\n",
        "# Get top-1 predicted index and confidence\n",
        "top1_idx = results[0].probs.top1\n",
        "top1_conf = results[0].probs.top1conf\n",
        "\n",
        "# Map index to class name\n",
        "# Filter out the 5th class if it exists\n",
        "class_names = [\"Hand_Painted\", \"Cartoon_Stylized\", \"Pixel_Art\", \"Vector_Art\"]\n",
        "if top1_idx >= len(class_names):\n",
        "    predicted_class = \"Unknown / Extra Class\"\n",
        "else:\n",
        "    predicted_class = class_names[top1_idx]\n",
        "\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "print(f\"Confidence: {top1_conf:.4f}\")"
      ],
      "metadata": {
        "id": "IacDaTFmWkyx",
        "outputId": "e9be73b9-535b-4cb1-c38e-554cf2d88d21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Hand_Painted\n",
            "Confidence: 1.0000\n"
          ]
        }
      ]
    }
  ]
}